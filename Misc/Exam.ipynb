{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다음과 같은 어레이를 Numpy를 이용하여 한 줄로 만드시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(0.,5.,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,11).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(n=3, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((4,4), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5,  7],\n",
       "       [ 9, 11, 13, 15],\n",
       "       [17, 19, 21, 23]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1, 24, 2).reshape(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다음과 같은 데이터프레임을 만드시오.\n",
    "- 단, 증가율은 계산으로 만들 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역</th>\n",
       "      <th>2015</th>\n",
       "      <th>2010</th>\n",
       "      <th>2005</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010-2015 증가율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>서울</th>\n",
       "      <td>수도권</td>\n",
       "      <td>9904312</td>\n",
       "      <td>9631482</td>\n",
       "      <td>9762546</td>\n",
       "      <td>9853972</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부산</th>\n",
       "      <td>경상권</td>\n",
       "      <td>3448737</td>\n",
       "      <td>3393191</td>\n",
       "      <td>3512547</td>\n",
       "      <td>3655437</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인천</th>\n",
       "      <td>수도권</td>\n",
       "      <td>2890451</td>\n",
       "      <td>2632035</td>\n",
       "      <td>2517680</td>\n",
       "      <td>2466338</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대구</th>\n",
       "      <td>경상권</td>\n",
       "      <td>2466052</td>\n",
       "      <td>2431774</td>\n",
       "      <td>2456016</td>\n",
       "      <td>2473990</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     지역     2015     2010     2005     2000  2010-2015 증가율\n",
       "서울  수도권  9904312  9631482  9762546  9853972         0.0283\n",
       "부산  경상권  3448737  3393191  3512547  3655437         0.0164\n",
       "인천  수도권  2890451  2632035  2517680  2466338         0.0982\n",
       "대구  경상권  2466052  2431774  2456016  2473990         0.0141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    \"2015\": [9904312, 3448737, 2890451, 2466052],\n",
    "    \"2010\": [9631482, 3393191, 2632035, 2431774],\n",
    "    \"2005\": [9762546, 3512547, 2517680, 2456016],\n",
    "    \"2000\": [9853972, 3655437, 2466338, 2473990],\n",
    "    \"지역\": [\"수도권\", \"경상권\", \"수도권\", \"경상권\"],\n",
    "}\n",
    "columns = [\"지역\", \"2015\", \"2010\", \"2005\", \"2000\"]\n",
    "index = [\"서울\", \"부산\", \"인천\", \"대구\"]\n",
    "df = pd.DataFrame(data, index=index, columns=columns)\n",
    "df['2010-2015 증가율'] = (df['2015'] / df['2010'] - 1).round(4)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 타이타닉호 승객에 대해서 다음을 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 성별(sex) 인원수, 선실별(class) 인원수, 사망/생존(alive) 인원수를 구하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Third     491\n",
       "First     216\n",
       "Second    184\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     549\n",
       "yes    342\n",
       "Name: alive, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.alive.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) '미성년자', '청년', '중년', '장년', '노년' 승객의 비율을 구하시오.<br>\n",
    "단, 나이의 기준은 [1, 15, 30, 45, 60, 99] 임.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "청년      0.311429\n",
       "중년      0.280000\n",
       "장년      0.278571\n",
       "미성년자    0.098571\n",
       "노년      0.031429\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [1, 15, 25, 35, 60, 99]\n",
    "labels = [\"미성년자\", \"청년\", \"중년\", \"장년\", \"노년\"]\n",
    "age_ = pd.cut(titanic['age'], bins, labels=labels)\n",
    "age_.dropna(inplace = True)\n",
    "pd.value_counts(age_)/sum(pd.value_counts(age_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 팁 데이터에 대해서 다음을 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 팁의 비율(단위 %)을 소숫점 2째자리까지 구하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>20.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>8.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size  tip_pct\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3    20.39\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2     7.36\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2     8.82\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2     9.82\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2    15.97"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips['tip_pct'] = (tips['tip'] / tips['total_bill'] * 100).round(2)\n",
    "tips.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) 팁의 비율이 가장 높은 날은 목, 금, 토, 일요일 중 어떤 날인지 피봇 테이블을\n",
    "      이용하여 구하시오.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Thur</th>\n",
       "      <td>16.126452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <td>16.991579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>15.314598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>16.689605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tip_pct\n",
       "day            \n",
       "Thur  16.126452\n",
       "Fri   16.991579\n",
       "Sat   15.314598\n",
       "Sun   16.689605"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.pivot_table('tip_pct','day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 다음의 지시대로 SQLite3를 이용하는 파이썬 프로그램을 작성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('./exam.db') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 필드로 [백넘버(PK), 이름, 포지션]을 갖는 테이블 Eagles를 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute('CREATE TABLE IF NOT EXISTS Eagles \\\n",
    "    (back_no INT NOT NULL, \\\n",
    "     name TEXT, \\\n",
    "     position TEXT, \\\n",
    "     PRIMARY KEY(back_no));')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) 1)번에서 만든 테이블에 (8, 정근우, 내야수)를 포함하여 임의로 5명의 선수를 삽입**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"INSERT INTO Eagles('back_no', 'name', 'position') \\\n",
    "             VALUES (8, '정근우', '내야수');\")\n",
    "cur.execute(\"INSERT INTO Eagles VALUES (30, '호잉', '외야수'), \\\n",
    "             (17, '김범수', '투수'), (38, '안영명', '투수'), \\\n",
    "             (13, '최재훈', '포수'), (43, '정은원', '내야수');\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) 2)번에서 입력한 선수 모두를 보여주는 프로그램**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '정근우', '내야수')\n",
      "(30, '호잉', '외야수')\n",
      "(17, '김범수', '투수')\n",
      "(38, '안영명', '투수')\n",
      "(13, '최재훈', '포수')\n",
      "(43, '정은원', '내야수')\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "sql = 'SELECT * FROM Eagles'\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) 정근우 선수의 포지션을 외야수로 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '정근우', '외야수')\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "sql = \"UPDATE Eagles SET position='외야수' WHERE back_no=8;\"\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "sql = 'SELECT * FROM Eagles WHERE back_no=8;'\n",
    "cur.execute(sql)\n",
    "row = cur.fetchone()\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) 선수중 백넘버가 가장 큰 선수를 삭제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "sql = 'SELECT back_no FROM Eagles ORDER BY back_no DESC LIMIT 1;'\n",
    "cur.execute(sql)\n",
    "max_no = cur.fetchone()\n",
    "max_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '정근우', '외야수')\n",
      "(30, '호잉', '외야수')\n",
      "(17, '김범수', '투수')\n",
      "(38, '안영명', '투수')\n",
      "(13, '최재훈', '포수')\n"
     ]
    }
   ],
   "source": [
    "sql = 'DELETE FROM Eagles WHERE back_no=?;'\n",
    "cur.execute(sql, max_no)       # cur.execute(sql, (max_no[0],))\n",
    "conn.commit()\n",
    "sql = 'SELECT * FROM Eagles'\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 시그모이드 함수와 시그모이드 함수를 미분한  함수의 그래프를 그리시오.\n",
    "- 단, x의 범위는 -3에서 +3까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def deri_sig(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-3, 3, 601)\n",
    "sig_Y = sigmoid(X)\n",
    "deri_sig_Y = deri_sig(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(X, sig_Y, color = 'red')\n",
    "plt.plot(X, deri_sig_Y, color = 'blue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 아이리스 데이터 셋을 이용하여 다음을 구하는 프로그램을 작성하시오.\n",
    "-  아이리스 데이터의 4가지 속성(꽃받침 길이/폭, 꽃잎 길이/폭)을 이용하여\n",
    "     품종을 예측\n",
    "- 단, 정확도는 98% 이상일 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "dataset = iris.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y_obj = dataset[:,4]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y = np_utils.to_categorical(Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "seed = 0\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# 모델 컴파일 \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 140us/step - loss: 0.1027 - acc: 0.9733\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0992 - acc: 0.9800\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.1034 - acc: 0.9667\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.1031 - acc: 0.9733\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0975 - acc: 0.9667\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.1093 - acc: 0.9667\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0974 - acc: 0.9667\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0989 - acc: 0.9733\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0949 - acc: 0.9800\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0964 - acc: 0.9667\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0948 - acc: 0.9800\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0966 - acc: 0.9800\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.1002 - acc: 0.9600\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0921 - acc: 0.9800\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0952 - acc: 0.9600\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0988 - acc: 0.9733\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0936 - acc: 0.9667\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0889 - acc: 0.9800\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0889 - acc: 0.9733\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0881 - acc: 0.9800\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0880 - acc: 0.9800\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0874 - acc: 0.9800\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0957 - acc: 0.9667\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0869 - acc: 0.9800\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0859 - acc: 0.9800\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0864 - acc: 0.9667\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0963 - acc: 0.9733\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0791 - acc: 0.9800\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0869 - acc: 0.9667\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0839 - acc: 0.9800\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0829 - acc: 0.9800\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0982 - acc: 0.9600\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0966 - acc: 0.9667\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0902 - acc: 0.9667\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0851 - acc: 0.9667\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0761 - acc: 0.9733\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0848 - acc: 0.9800\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0797 - acc: 0.9800\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.0791 - acc: 0.9867\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0790 - acc: 0.9800\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0815 - acc: 0.9600\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0780 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0787 - acc: 0.9733\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0806 - acc: 0.9800\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0992 - acc: 0.9600\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0811 - acc: 0.9733\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0825 - acc: 0.9667\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0876 - acc: 0.9733\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0782 - acc: 0.9867\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0733 - acc: 0.9800\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0787 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0739 - acc: 0.9800\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0746 - acc: 0.9867\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0789 - acc: 0.9667\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0724 - acc: 0.9800\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0801 - acc: 0.9800\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0772 - acc: 0.9800\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0732 - acc: 0.9800\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0720 - acc: 0.9867\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0757 - acc: 0.9800\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0722 - acc: 0.9800\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0816 - acc: 0.9667\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0727 - acc: 0.9733\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0738 - acc: 0.9733\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0708 - acc: 0.9867\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0737 - acc: 0.9800\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0812 - acc: 0.9800\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0671 - acc: 0.9800\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0742 - acc: 0.9733\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0707 - acc: 0.9800\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0718 - acc: 0.9800\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0088 - acc: 1.000 - 0s 87us/step - loss: 0.0716 - acc: 0.9733\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0732 - acc: 0.9733\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0760 - acc: 0.9667\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0761 - acc: 0.9800\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0659 - acc: 0.9800\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0690 - acc: 0.9733\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0807 - acc: 0.9733\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0806 - acc: 0.9600\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0799 - acc: 0.9800\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0682 - acc: 0.9800\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0688 - acc: 0.9800\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0683 - acc: 0.9867\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/step - loss: 0.0669 - acc: 0.9800\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0693 - acc: 0.9800\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0721 - acc: 0.9733\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.0669 - acc: 0.9800\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0734 - acc: 0.9733\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0688 - acc: 0.9800\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0666 - acc: 0.9800\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0652 - acc: 0.9867\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0672 - acc: 0.9800\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.0702 - acc: 0.9733\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0656 - acc: 0.9800\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0102 - acc: 1.000 - 0s 80us/step - loss: 0.0663 - acc: 0.9800\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0689 - acc: 0.9867\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0688 - acc: 0.9800\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0661 - acc: 0.9800\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.0657 - acc: 0.9867\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.0695 - acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fb8198>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/step\n",
      "\n",
      " Accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 피마 인디언 데이터 셋을 이용하여 다음을 구하는 프로그램을 작성하시오.\n",
    "- 피마 인디언 데이터의 8가지 속성을 이용하여 당뇨병 여부를 판단할 것\n",
    "- 단, 데이터의 25%는 테스트 데이터로 사용하여 정확도를 구할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
       "0         6     148        72         35        0  33.6     0.627   50      1\n",
       "1         1      85        66         29        0  26.6     0.351   31      0\n",
       "2         8     183        64          0        0  23.3     0.672   32      1\n",
       "3         1      89        66         23       94  28.1     0.167   21      0\n",
       "4         0     137        40         35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv',\n",
    "                 names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\",  \n",
    "                 \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 생성\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 472us/step - loss: 2.6810 - acc: 0.4375\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.9872 - acc: 0.6337\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.8759 - acc: 0.6563\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.8195 - acc: 0.6285\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.7722 - acc: 0.6250\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.7378 - acc: 0.6111\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.7126 - acc: 0.6319\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.6809 - acc: 0.6302\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6477 - acc: 0.6545\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6323 - acc: 0.6424\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6136 - acc: 0.6615\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.6274 - acc: 0.6285\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.6241 - acc: 0.6510\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.6100 - acc: 0.6389\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6145 - acc: 0.6736\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.6113 - acc: 0.6788\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.6029 - acc: 0.6892\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.6076 - acc: 0.6563\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6048 - acc: 0.6493\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.6020 - acc: 0.6667\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6087 - acc: 0.6615\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5914 - acc: 0.6823\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.6016 - acc: 0.6736\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5882 - acc: 0.6684\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5923 - acc: 0.6875\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5913 - acc: 0.6875\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5885 - acc: 0.6736\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5855 - acc: 0.7031\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5889 - acc: 0.6823\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5797 - acc: 0.6823\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5804 - acc: 0.6753\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5934 - acc: 0.6875\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.5865 - acc: 0.6771\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5711 - acc: 0.6997\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.5754 - acc: 0.7031\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5658 - acc: 0.7031\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5683 - acc: 0.6753\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5636 - acc: 0.7118\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5611 - acc: 0.6979\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5666 - acc: 0.6979\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5621 - acc: 0.7118\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5687 - acc: 0.7031\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5703 - acc: 0.6927\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5655 - acc: 0.6858\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5645 - acc: 0.6910\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5514 - acc: 0.7187\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5508 - acc: 0.7135\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5456 - acc: 0.7153\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5651 - acc: 0.6979\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5541 - acc: 0.7014\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5577 - acc: 0.7222\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5547 - acc: 0.7240\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5620 - acc: 0.6944\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5484 - acc: 0.7083\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5607 - acc: 0.7222\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5628 - acc: 0.7135\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5460 - acc: 0.7153\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5440 - acc: 0.7222\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5465 - acc: 0.7153\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5514 - acc: 0.6962\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5415 - acc: 0.7101\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5509 - acc: 0.7031\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5632 - acc: 0.7083\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5419 - acc: 0.7188\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5534 - acc: 0.7170\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5354 - acc: 0.7135\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5424 - acc: 0.7257\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5537 - acc: 0.7049\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5464 - acc: 0.7083\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5559 - acc: 0.7066\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5578 - acc: 0.7049\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5637 - acc: 0.7153\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5463 - acc: 0.7240\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5326 - acc: 0.7378\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5418 - acc: 0.7413\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5397 - acc: 0.7396\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5539 - acc: 0.7222\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5001 - acc: 0.800 - 0s 76us/step - loss: 0.5274 - acc: 0.7240\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5339 - acc: 0.7188\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5439 - acc: 0.7205\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5671 - acc: 0.7222\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5372 - acc: 0.7292\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5308 - acc: 0.7309\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 75us/step - loss: 0.5404 - acc: 0.7135\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5313 - acc: 0.7378\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5310 - acc: 0.7396\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5354 - acc: 0.7292\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5224 - acc: 0.7292\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5227 - acc: 0.7240\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5247 - acc: 0.7257\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5245 - acc: 0.7257\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5280 - acc: 0.7378\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5193 - acc: 0.7292\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5234 - acc: 0.7292\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5175 - acc: 0.7292\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5263 - acc: 0.7240\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5219 - acc: 0.7448\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5131 - acc: 0.7378\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5155 - acc: 0.7378\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5094 - acc: 0.7361\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5255 - acc: 0.7344\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5371 - acc: 0.7135\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5179 - acc: 0.7378\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5167 - acc: 0.7396\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5204 - acc: 0.7292\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5206 - acc: 0.7413\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5164 - acc: 0.7483\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5143 - acc: 0.7465\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5199 - acc: 0.7483\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5083 - acc: 0.7431\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5390 - acc: 0.7066\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5135 - acc: 0.7517\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5220 - acc: 0.7378\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5334 - acc: 0.7326\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5139 - acc: 0.7309\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5095 - acc: 0.7535\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.5141 - acc: 0.7483\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.5207 - acc: 0.7326\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5109 - acc: 0.7396\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.5119 - acc: 0.7344\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5254 - acc: 0.7309\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5096 - acc: 0.7587\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5214 - acc: 0.7378\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5164 - acc: 0.7344\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5112 - acc: 0.7413\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5201 - acc: 0.7483\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5119 - acc: 0.7361\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5032 - acc: 0.7396\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5126 - acc: 0.7500\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5007 - acc: 0.7431\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5036 - acc: 0.7587\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.5052 - acc: 0.7326\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5021 - acc: 0.7483\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5044 - acc: 0.7465\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5117 - acc: 0.7344\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5199 - acc: 0.7448\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5040 - acc: 0.7535\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4963 - acc: 0.7448\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5034 - acc: 0.7569\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4980 - acc: 0.7569\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5069 - acc: 0.7361\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5095 - acc: 0.7378\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4910 - acc: 0.7552\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5236 - acc: 0.7240\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5146 - acc: 0.7465\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5067 - acc: 0.7535\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.5118 - acc: 0.7465\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4936 - acc: 0.7656\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4949 - acc: 0.7569\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5010 - acc: 0.7431\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4986 - acc: 0.7500\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4922 - acc: 0.7639\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4975 - acc: 0.7448\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4948 - acc: 0.7517\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4849 - acc: 0.7604\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5009 - acc: 0.7569\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4950 - acc: 0.7622\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4853 - acc: 0.7517\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4939 - acc: 0.7483\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4845 - acc: 0.7639\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4869 - acc: 0.7465\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5009 - acc: 0.7535\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.5000 - acc: 0.7587\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4868 - acc: 0.7639\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4927 - acc: 0.7535\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4861 - acc: 0.7622\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 76us/step - loss: 0.4995 - acc: 0.7517\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4834 - acc: 0.7639\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4902 - acc: 0.7622\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4832 - acc: 0.7552\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4796 - acc: 0.7656\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4800 - acc: 0.7639\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4835 - acc: 0.7674\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4826 - acc: 0.7743\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4798 - acc: 0.7847\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4900 - acc: 0.7569\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4924 - acc: 0.7830\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4815 - acc: 0.7535\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4802 - acc: 0.7656\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4865 - acc: 0.7708\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4886 - acc: 0.7760\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4886 - acc: 0.7622\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4815 - acc: 0.7726\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4824 - acc: 0.7656\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4796 - acc: 0.7604\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4782 - acc: 0.7708\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4887 - acc: 0.7465\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4809 - acc: 0.7674\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4851 - acc: 0.7656\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4775 - acc: 0.7743\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4783 - acc: 0.7760\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4970 - acc: 0.7552\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4865 - acc: 0.7604\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4802 - acc: 0.7656\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4825 - acc: 0.7708\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.5075 - acc: 0.7448\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4840 - acc: 0.7622\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4735 - acc: 0.7865\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.4730 - acc: 0.7795\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4796 - acc: 0.7639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1150c320>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 266us/step\n",
      "\n",
      " Accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
